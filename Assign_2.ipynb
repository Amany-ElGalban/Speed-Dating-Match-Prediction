{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8ZuhnBgdbP8"
      },
      "source": [
        " ---\n",
        " ---\n",
        "   **Problem Formulation** \n",
        "\n",
        " ---\n",
        " ---\n",
        "\n",
        "*  **The input:** \n",
        " *  Training dat (df) : it containd the features and the label data.\n",
        " *  Testing data (df2) : it contains the features.\n",
        "\n",
        "* **the output**\n",
        " * it will be the label data (the raiting column) \n",
        "\n",
        "*  **Function used**  \n",
        " *   classification\n",
        "\n",
        " *   predection\n",
        "\n",
        "*   **Challenges**\n",
        "\n",
        " *   The dataset is not clean, and we need some preprocessing depending on the models we choice,\n",
        " \n",
        " - changing the multipul  hyperparameter to give a good accuracy/f1 score\n",
        "\n",
        "*    **the imapct** \n",
        " *   the impact that the model will fits will on the training data and predect well on the test data or any data that we enter, And that will have a huge impact in real life if that uesd we will be able to predect right and proratize what is important.\n",
        " \n",
        " - we are going to be able to evaluate our mdels correctly and we can help the customer to find what they really want. \n",
        "\n",
        "\n",
        "*    **ideal solution**\n",
        " *   the ideal solutition happens when our model is able to classify and predict very well on any data the model gets , And also that happens when our data is cleaned perfectly  and \n",
        "\n",
        " - it happens when choose the perfecrt model who can deals with type of dat and not to forget the gyperparameter tuning .\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNB2_AU5n5BC"
      },
      "source": [
        "---\n",
        "---\n",
        "#**Importing libraries**\n",
        "\n",
        "----\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pLjnxjG3xYiU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "from sklearn.model_selection import train_test_split\n",
        "# import to RFE that return best columns\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "\n",
        "# import packages for hyperparameters tuning\n",
        "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.model_selection import PredefinedSplit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-DBEswE6xh4T"
      },
      "outputs": [],
      "source": [
        "#reading traingi data\n",
        "data = pd.read_csv('/content/drive/MyDrive/DM_assignment2/train.csv')\n",
        "#reading testing  data\n",
        "test = pd.read_csv('/content/drive/MyDrive/DM_assignment2/test.csv')\n",
        "id_ = test.id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KmgtASzxAWr"
      },
      "source": [
        "---\n",
        "---\n",
        "#**over view of the data**\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "wbvODUVlxh7E",
        "outputId": "8e1a9e7a-9bc6-4059-8670-ba0a1290998c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b0831544-d23b-4ad3-9d50-25e91f63da32\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>idg</th>\n",
              "      <th>condtn</th>\n",
              "      <th>wave</th>\n",
              "      <th>round</th>\n",
              "      <th>position</th>\n",
              "      <th>positin1</th>\n",
              "      <th>order</th>\n",
              "      <th>partner</th>\n",
              "      <th>pid</th>\n",
              "      <th>...</th>\n",
              "      <th>sinc3_3</th>\n",
              "      <th>intel3_3</th>\n",
              "      <th>fun3_3</th>\n",
              "      <th>amb3_3</th>\n",
              "      <th>attr5_3</th>\n",
              "      <th>sinc5_3</th>\n",
              "      <th>intel5_3</th>\n",
              "      <th>fun5_3</th>\n",
              "      <th>amb5_3</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>14</td>\n",
              "      <td>12</td>\n",
              "      <td>372.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>63.0</td>\n",
              "      <td>...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>331.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>18</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>200.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>20</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20</td>\n",
              "      <td>17</td>\n",
              "      <td>357.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4828</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 192 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0831544-d23b-4ad3-9d50-25e91f63da32')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b0831544-d23b-4ad3-9d50-25e91f63da32 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b0831544-d23b-4ad3-9d50-25e91f63da32');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   gender  idg  condtn  wave  round  position  positin1  order  partner  \\\n",
              "0       0    3       2    14     18         2       2.0     14       12   \n",
              "1       1   14       1     3     10         2       NaN      8        8   \n",
              "2       1   14       1    13     10         8       8.0     10       10   \n",
              "3       1   38       2     9     20        18      13.0      6        7   \n",
              "4       1   24       2    14     20         6       6.0     20       17   \n",
              "\n",
              "     pid  ...  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  sinc5_3  intel5_3  \\\n",
              "0  372.0  ...      NaN       NaN     NaN     NaN      NaN      NaN       NaN   \n",
              "1   63.0  ...      8.0       8.0     7.0     8.0      NaN      NaN       NaN   \n",
              "2  331.0  ...      NaN       NaN     NaN     NaN      NaN      NaN       NaN   \n",
              "3  200.0  ...      9.0       8.0     8.0     6.0      NaN      NaN       NaN   \n",
              "4  357.0  ...      NaN       NaN     NaN     NaN      NaN      NaN       NaN   \n",
              "\n",
              "   fun5_3  amb5_3    id  \n",
              "0     NaN     NaN  2583  \n",
              "1     NaN     NaN  6830  \n",
              "2     NaN     NaN  4840  \n",
              "3     NaN     NaN  5508  \n",
              "4     NaN     NaN  4828  \n",
              "\n",
              "[5 rows x 192 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# to show the first 5 rows of data\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "w-RpiniOFJ5f",
        "outputId": "3085b74d-b785-4a02-82c2-ad187c46433a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-41d96416-c442-45e4-8cc6-766201d89ea2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>idg</th>\n",
              "      <th>condtn</th>\n",
              "      <th>wave</th>\n",
              "      <th>round</th>\n",
              "      <th>position</th>\n",
              "      <th>positin1</th>\n",
              "      <th>order</th>\n",
              "      <th>partner</th>\n",
              "      <th>pid</th>\n",
              "      <th>...</th>\n",
              "      <th>sinc3_3</th>\n",
              "      <th>intel3_3</th>\n",
              "      <th>fun3_3</th>\n",
              "      <th>amb3_3</th>\n",
              "      <th>attr5_3</th>\n",
              "      <th>sinc5_3</th>\n",
              "      <th>intel5_3</th>\n",
              "      <th>fun5_3</th>\n",
              "      <th>amb5_3</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>52.0</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>18</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>368.0</td>\n",
              "      <td>...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>16.0</td>\n",
              "      <td>15</td>\n",
              "      <td>19</td>\n",
              "      <td>212.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>30.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>16</td>\n",
              "      <td>7</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>162.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1052</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 191 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41d96416-c442-45e4-8cc6-766201d89ea2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41d96416-c442-45e4-8cc6-766201d89ea2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41d96416-c442-45e4-8cc6-766201d89ea2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   gender  idg  condtn  wave  round  position  positin1  order  partner  \\\n",
              "0       0    5       2     2     16         3       NaN     13       13   \n",
              "1       0   33       2    14     18         6       6.0      4        8   \n",
              "2       1    6       2     9     20        10      16.0     15       19   \n",
              "3       1   26       2     2     19        15       NaN      8       10   \n",
              "4       0   29       2     7     16         7       7.0     10        5   \n",
              "\n",
              "     pid  ...  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  sinc5_3  intel5_3  \\\n",
              "0   52.0  ...      7.0       8.0     6.0     8.0      NaN      NaN       NaN   \n",
              "1  368.0  ...      8.0       7.0     7.0     8.0      6.0      7.0       6.0   \n",
              "2  212.0  ...      NaN       NaN     NaN     NaN      NaN      NaN       NaN   \n",
              "3   30.0  ...      NaN       NaN     NaN     NaN      NaN      NaN       NaN   \n",
              "4  162.0  ...      NaN       NaN     NaN     NaN      NaN      NaN       NaN   \n",
              "\n",
              "   fun5_3  amb5_3    id  \n",
              "0     NaN     NaN   934  \n",
              "1     5.0     5.0  6539  \n",
              "2     NaN     NaN  6757  \n",
              "3     NaN     NaN  2275  \n",
              "4     NaN     NaN  1052  \n",
              "\n",
              "[5 rows x 191 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# to show the first 5 rows of data\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aY4C1p7xh9q",
        "outputId": "5468d859-6f40-4022-a026-ae51d241e644"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5909, 192)\n",
            "(2469, 191)\n"
          ]
        }
      ],
      "source": [
        "# printing the shape of train and test data\n",
        "print(data.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "N-IUSivBxiAC",
        "outputId": "2e0b0cae-f736-40d8-ede3-3f559242218c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0ff5b08a-1900-47c3-93c1-00be92b8ed85\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>idg</th>\n",
              "      <th>condtn</th>\n",
              "      <th>wave</th>\n",
              "      <th>round</th>\n",
              "      <th>position</th>\n",
              "      <th>positin1</th>\n",
              "      <th>order</th>\n",
              "      <th>partner</th>\n",
              "      <th>pid</th>\n",
              "      <th>...</th>\n",
              "      <th>sinc3_3</th>\n",
              "      <th>intel3_3</th>\n",
              "      <th>fun3_3</th>\n",
              "      <th>amb3_3</th>\n",
              "      <th>attr5_3</th>\n",
              "      <th>sinc5_3</th>\n",
              "      <th>intel5_3</th>\n",
              "      <th>fun5_3</th>\n",
              "      <th>amb5_3</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5909.000000</td>\n",
              "      <td>5909.000000</td>\n",
              "      <td>5909.000000</td>\n",
              "      <td>5909.000000</td>\n",
              "      <td>5909.000000</td>\n",
              "      <td>5909.000000</td>\n",
              "      <td>4591.000000</td>\n",
              "      <td>5909.00000</td>\n",
              "      <td>5909.000000</td>\n",
              "      <td>5901.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2804.000000</td>\n",
              "      <td>2804.000000</td>\n",
              "      <td>2804.000000</td>\n",
              "      <td>2804.000000</td>\n",
              "      <td>1413.000000</td>\n",
              "      <td>1413.000000</td>\n",
              "      <td>1413.000000</td>\n",
              "      <td>1413.000000</td>\n",
              "      <td>1413.000000</td>\n",
              "      <td>5909.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.505331</td>\n",
              "      <td>17.360298</td>\n",
              "      <td>1.824843</td>\n",
              "      <td>11.347436</td>\n",
              "      <td>16.850228</td>\n",
              "      <td>9.001523</td>\n",
              "      <td>9.254846</td>\n",
              "      <td>8.91166</td>\n",
              "      <td>8.962938</td>\n",
              "      <td>283.733266</td>\n",
              "      <td>...</td>\n",
              "      <td>8.105563</td>\n",
              "      <td>8.377318</td>\n",
              "      <td>7.644437</td>\n",
              "      <td>7.398716</td>\n",
              "      <td>6.799717</td>\n",
              "      <td>7.631989</td>\n",
              "      <td>7.944798</td>\n",
              "      <td>7.162774</td>\n",
              "      <td>7.092711</td>\n",
              "      <td>4191.314943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.500014</td>\n",
              "      <td>10.947542</td>\n",
              "      <td>0.380133</td>\n",
              "      <td>6.011495</td>\n",
              "      <td>4.389246</td>\n",
              "      <td>5.482368</td>\n",
              "      <td>5.611803</td>\n",
              "      <td>5.45710</td>\n",
              "      <td>5.500706</td>\n",
              "      <td>158.993002</td>\n",
              "      <td>...</td>\n",
              "      <td>1.601011</td>\n",
              "      <td>1.459013</td>\n",
              "      <td>1.757559</td>\n",
              "      <td>1.956924</td>\n",
              "      <td>1.535768</td>\n",
              "      <td>1.498024</td>\n",
              "      <td>1.320919</td>\n",
              "      <td>1.687431</td>\n",
              "      <td>1.713729</td>\n",
              "      <td>2408.009173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2124.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>8.00000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>280.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>4210.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>13.00000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>409.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6266.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>22.00000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>552.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>8372.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 184 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ff5b08a-1900-47c3-93c1-00be92b8ed85')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0ff5b08a-1900-47c3-93c1-00be92b8ed85 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0ff5b08a-1900-47c3-93c1-00be92b8ed85');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            gender          idg       condtn         wave        round  \\\n",
              "count  5909.000000  5909.000000  5909.000000  5909.000000  5909.000000   \n",
              "mean      0.505331    17.360298     1.824843    11.347436    16.850228   \n",
              "std       0.500014    10.947542     0.380133     6.011495     4.389246   \n",
              "min       0.000000     1.000000     1.000000     1.000000     5.000000   \n",
              "25%       0.000000     8.000000     2.000000     7.000000    14.000000   \n",
              "50%       1.000000    16.000000     2.000000    11.000000    18.000000   \n",
              "75%       1.000000    26.000000     2.000000    15.000000    20.000000   \n",
              "max       1.000000    44.000000     2.000000    21.000000    22.000000   \n",
              "\n",
              "          position     positin1       order      partner          pid  ...  \\\n",
              "count  5909.000000  4591.000000  5909.00000  5909.000000  5901.000000  ...   \n",
              "mean      9.001523     9.254846     8.91166     8.962938   283.733266  ...   \n",
              "std       5.482368     5.611803     5.45710     5.500706   158.993002  ...   \n",
              "min       1.000000     1.000000     1.00000     1.000000     1.000000  ...   \n",
              "25%       4.000000     4.000000     4.00000     4.000000   153.000000  ...   \n",
              "50%       8.000000     9.000000     8.00000     8.000000   280.000000  ...   \n",
              "75%      13.000000    14.000000    13.00000    13.000000   409.000000  ...   \n",
              "max      22.000000    22.000000    22.00000    22.000000   552.000000  ...   \n",
              "\n",
              "           sinc3_3     intel3_3       fun3_3       amb3_3      attr5_3  \\\n",
              "count  2804.000000  2804.000000  2804.000000  2804.000000  1413.000000   \n",
              "mean      8.105563     8.377318     7.644437     7.398716     6.799717   \n",
              "std       1.601011     1.459013     1.757559     1.956924     1.535768   \n",
              "min       2.000000     3.000000     2.000000     1.000000     2.000000   \n",
              "25%       7.000000     8.000000     7.000000     6.000000     6.000000   \n",
              "50%       8.000000     8.000000     8.000000     8.000000     7.000000   \n",
              "75%       9.000000     9.000000     9.000000     9.000000     8.000000   \n",
              "max      12.000000    12.000000    12.000000    12.000000    10.000000   \n",
              "\n",
              "           sinc5_3     intel5_3       fun5_3       amb5_3           id  \n",
              "count  1413.000000  1413.000000  1413.000000  1413.000000  5909.000000  \n",
              "mean      7.631989     7.944798     7.162774     7.092711  4191.314943  \n",
              "std       1.498024     1.320919     1.687431     1.713729  2408.009173  \n",
              "min       2.000000     4.000000     1.000000     1.000000     0.000000  \n",
              "25%       7.000000     7.000000     6.000000     6.000000  2124.000000  \n",
              "50%       8.000000     8.000000     7.000000     7.000000  4210.000000  \n",
              "75%       9.000000     9.000000     8.000000     8.000000  6266.000000  \n",
              "max      10.000000    10.000000    10.000000    10.000000  8372.000000  \n",
              "\n",
              "[8 rows x 184 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#a full describetion of the data\n",
        "data.describe()\n",
        "# theis line to get the full decribtion even with string values \n",
        "#data.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "slXcT8x4E4-B",
        "outputId": "68c6b72c-d180-4ddf-9a6c-e147cf71e1c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-187b73fa-d16a-448c-b237-0cb73257523f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>idg</th>\n",
              "      <th>condtn</th>\n",
              "      <th>wave</th>\n",
              "      <th>round</th>\n",
              "      <th>position</th>\n",
              "      <th>positin1</th>\n",
              "      <th>order</th>\n",
              "      <th>partner</th>\n",
              "      <th>pid</th>\n",
              "      <th>...</th>\n",
              "      <th>sinc3_3</th>\n",
              "      <th>intel3_3</th>\n",
              "      <th>fun3_3</th>\n",
              "      <th>amb3_3</th>\n",
              "      <th>attr5_3</th>\n",
              "      <th>sinc5_3</th>\n",
              "      <th>intel5_3</th>\n",
              "      <th>fun5_3</th>\n",
              "      <th>amb5_3</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2469.000000</td>\n",
              "      <td>2469.000000</td>\n",
              "      <td>2469.000000</td>\n",
              "      <td>2469.000000</td>\n",
              "      <td>2469.000000</td>\n",
              "      <td>2469.000000</td>\n",
              "      <td>1941.000000</td>\n",
              "      <td>2469.000000</td>\n",
              "      <td>2469.000000</td>\n",
              "      <td>2467.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1170.000000</td>\n",
              "      <td>1170.000000</td>\n",
              "      <td>1170.000000</td>\n",
              "      <td>1170.000000</td>\n",
              "      <td>603.000000</td>\n",
              "      <td>603.000000</td>\n",
              "      <td>603.000000</td>\n",
              "      <td>603.000000</td>\n",
              "      <td>603.000000</td>\n",
              "      <td>2469.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.489267</td>\n",
              "      <td>17.247874</td>\n",
              "      <td>1.838396</td>\n",
              "      <td>11.359255</td>\n",
              "      <td>16.924261</td>\n",
              "      <td>9.141353</td>\n",
              "      <td>9.392581</td>\n",
              "      <td>8.965978</td>\n",
              "      <td>8.965168</td>\n",
              "      <td>284.175922</td>\n",
              "      <td>...</td>\n",
              "      <td>8.064103</td>\n",
              "      <td>8.416239</td>\n",
              "      <td>7.693162</td>\n",
              "      <td>7.374359</td>\n",
              "      <td>6.834163</td>\n",
              "      <td>7.575456</td>\n",
              "      <td>7.903814</td>\n",
              "      <td>7.137645</td>\n",
              "      <td>6.945274</td>\n",
              "      <td>4181.763062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.499986</td>\n",
              "      <td>10.926235</td>\n",
              "      <td>0.368162</td>\n",
              "      <td>5.959627</td>\n",
              "      <td>4.284307</td>\n",
              "      <td>5.592006</td>\n",
              "      <td>5.740292</td>\n",
              "      <td>5.525290</td>\n",
              "      <td>5.469045</td>\n",
              "      <td>157.636121</td>\n",
              "      <td>...</td>\n",
              "      <td>1.632694</td>\n",
              "      <td>1.459546</td>\n",
              "      <td>1.713641</td>\n",
              "      <td>1.972877</td>\n",
              "      <td>1.439486</td>\n",
              "      <td>1.520249</td>\n",
              "      <td>1.387187</td>\n",
              "      <td>1.639208</td>\n",
              "      <td>1.724936</td>\n",
              "      <td>2444.455043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>157.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2040.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>283.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>4137.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>405.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6316.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>552.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>8377.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 183 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-187b73fa-d16a-448c-b237-0cb73257523f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-187b73fa-d16a-448c-b237-0cb73257523f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-187b73fa-d16a-448c-b237-0cb73257523f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            gender          idg       condtn         wave        round  \\\n",
              "count  2469.000000  2469.000000  2469.000000  2469.000000  2469.000000   \n",
              "mean      0.489267    17.247874     1.838396    11.359255    16.924261   \n",
              "std       0.499986    10.926235     0.368162     5.959627     4.284307   \n",
              "min       0.000000     1.000000     1.000000     1.000000     5.000000   \n",
              "25%       0.000000     8.000000     2.000000     7.000000    14.000000   \n",
              "50%       0.000000    16.000000     2.000000    11.000000    18.000000   \n",
              "75%       1.000000    26.000000     2.000000    15.000000    20.000000   \n",
              "max       1.000000    44.000000     2.000000    21.000000    22.000000   \n",
              "\n",
              "          position     positin1        order      partner          pid  ...  \\\n",
              "count  2469.000000  1941.000000  2469.000000  2469.000000  2467.000000  ...   \n",
              "mean      9.141353     9.392581     8.965978     8.965168   284.175922  ...   \n",
              "std       5.592006     5.740292     5.525290     5.469045   157.636121  ...   \n",
              "min       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
              "25%       4.000000     4.000000     4.000000     4.000000   157.000000  ...   \n",
              "50%       8.000000     9.000000     8.000000     8.000000   283.000000  ...   \n",
              "75%      13.000000    14.000000    13.000000    13.000000   405.000000  ...   \n",
              "max      22.000000    22.000000    22.000000    22.000000   552.000000  ...   \n",
              "\n",
              "           sinc3_3     intel3_3       fun3_3       amb3_3     attr5_3  \\\n",
              "count  1170.000000  1170.000000  1170.000000  1170.000000  603.000000   \n",
              "mean      8.064103     8.416239     7.693162     7.374359    6.834163   \n",
              "std       1.632694     1.459546     1.713641     1.972877    1.439486   \n",
              "min       2.000000     3.000000     2.000000     1.000000    2.000000   \n",
              "25%       7.000000     8.000000     7.000000     6.000000    6.000000   \n",
              "50%       8.000000     8.000000     8.000000     8.000000    7.000000   \n",
              "75%       9.000000     9.000000     9.000000     9.000000    8.000000   \n",
              "max      12.000000    12.000000    12.000000    12.000000   10.000000   \n",
              "\n",
              "          sinc5_3    intel5_3      fun5_3      amb5_3           id  \n",
              "count  603.000000  603.000000  603.000000  603.000000  2469.000000  \n",
              "mean     7.575456    7.903814    7.137645    6.945274  4181.763062  \n",
              "std      1.520249    1.387187    1.639208    1.724936  2444.455043  \n",
              "min      2.000000    4.000000    1.000000    1.000000     3.000000  \n",
              "25%      7.000000    7.000000    6.000000    6.000000  2040.000000  \n",
              "50%      8.000000    8.000000    7.000000    7.000000  4137.000000  \n",
              "75%      9.000000    9.000000    8.000000    8.000000  6316.000000  \n",
              "max     10.000000   10.000000   10.000000   10.000000  8377.000000  \n",
              "\n",
              "[8 rows x 183 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#a full describetion of the data\n",
        "test.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiA-cy2NxiEz",
        "outputId": "a314a498-2d73-41e5-c969-6685898b0fda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "num_in_3    5449\n",
              "numdat_3    4849\n",
              "expnum      4627\n",
              "amb7_2      4519\n",
              "sinc7_2     4519\n",
              "            ... \n",
              "position       0\n",
              "round          0\n",
              "wave           0\n",
              "condtn         0\n",
              "id             0\n",
              "Length: 192, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#checking if there is any null values and getting the sum in every column\n",
        "data.isnull().sum().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWkg8Lao3RrE",
        "outputId": "0316909d-2785-4ff6-c9cd-ce4b0a14566c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5909 entries, 0 to 5908\n",
            "Columns: 192 entries, gender to id\n",
            "dtypes: float64(173), int64(11), object(8)\n",
            "memory usage: 8.7+ MB\n"
          ]
        }
      ],
      "source": [
        "#getting a full sammry of the train data \n",
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVBegLNRWb5s"
      },
      "source": [
        "we realized we have 8 objest values and we need to change their vlaues to numeric later.  \n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNovxBUTF0VX",
        "outputId": "f1ebfae1-872a-4873-e2cf-e20b74c6dfe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2469 entries, 0 to 2468\n",
            "Columns: 191 entries, gender to id\n",
            "dtypes: float64(173), int64(10), object(8)\n",
            "memory usage: 3.6+ MB\n"
          ]
        }
      ],
      "source": [
        "# getting a full summary of the test data \n",
        "test.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OLPxCXkMRh5"
      },
      "source": [
        "the same as the training  data we found the same values.\n",
        "\n",
        "----\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBGAmODU1HxU",
        "outputId": "0803744d-0e83-45d0-dcce-7bdae69cfe87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gender         2\n",
              "idg           44\n",
              "condtn         2\n",
              "wave          21\n",
              "round         15\n",
              "            ... \n",
              "sinc5_3        9\n",
              "intel5_3       7\n",
              "fun5_3        10\n",
              "amb5_3         9\n",
              "id          5909\n",
              "Length: 192, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# to get the sum of unique values in every column\n",
        "data.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt30oXXmxiJL",
        "outputId": "bc2db4c8-c813-4809-c72c-b4d204ebb57f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index([], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "#check for a clumn with only one unique values  \n",
        "print(data.loc[:,data.nunique()==1].keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ODdKh4p-MwYm"
      },
      "outputs": [],
      "source": [
        "# # #convert all object columns to categorical column\n",
        "# data[data.select_dtypes(['object']).columns] = data.select_dtypes(['object']).apply(lambda x: x.astype('category'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJWVd2QKxZhx"
      },
      "source": [
        "---\n",
        "---\n",
        "#**Preprocessing**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCR-vb5DPvoX"
      },
      "source": [
        "---\n",
        "**After reading the data i realized:**\n",
        "\n",
        "- There is a alot of missing values.\n",
        "- String values\n",
        "- colums that not really necessary like the ( id )  \n",
        "---\n",
        "\n",
        "**Here im planing to** :\n",
        "\n",
        "1) split the training data to features and and label.\n",
        "\n",
        "2) Droping the columns that doesn't affect in the features.\n",
        "\n",
        "3) put the numeric values and categorical data speratly. and that will help working in the categorical data when we want to change it to numerical.\n",
        "\n",
        "4) Full PIPLINE : IT has the main preprocessig feaatures such as: \n",
        "  - Fill Nan values \n",
        "  - standard scaler\n",
        "  - one HotEncoding \n",
        "---\n",
        "**the experimental protocol used is 'Hold out method'**\n",
        "\n",
        "The following is the process of using the hold-out method for model evaluation:\n",
        "\n",
        "- Split the dataset into two parts (preferably based on 70-30% split; However, the percentage split will vary)\n",
        "\n",
        "- Train the model on the training dataset; While training the model, some fixed set of hyper parameters is selected.\n",
        "\n",
        "- Test or evaluate the model on the held-out test dataset\n",
        "Train the final model on the entire dataset to get a model which can generalize better on the unseen or future dataset. \n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWjlzownxkOK"
      },
      "source": [
        "---\n",
        "###**Splitting training data** \n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tePBaL4sxiLy",
        "outputId": "b42fa59a-ebe1-414e-ae17-80c63e8394ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original shape (5909, 190) (5909,)\n"
          ]
        }
      ],
      "source": [
        "#splitting the teaining data to x,y (features and label/output) \n",
        "#and also droppin the id fron the x\n",
        "y = data['match'] # lower case for vector\n",
        "X = data.drop(['id','match'], axis=1) # upper case for matrix\n",
        "print('original shape', X.shape, y.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgPl_NAPxvH6"
      },
      "source": [
        "---\n",
        "###**Dropping the id coulum**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ummDvZqfx1la"
      },
      "source": [
        "we are dropping the id column from the training data and testing data, it's not really necessry to use it so we can drop it \n",
        "\n",
        " ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Almpi5uDFWE2",
        "outputId": "32416a99-3ff2-4923-d780-9fd9807c490a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original shape (2469, 190)\n"
          ]
        }
      ],
      "source": [
        "# dropping id from testing data\n",
        "test.drop('id',axis=1,inplace=True)\n",
        "print('original shape', test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Kim4FYV_IEsm"
      },
      "outputs": [],
      "source": [
        "# #convert all object columns to categorical column\n",
        "# data[data.select_dtypes(['object']).columns] = data.select_dtypes(['object']).apply(lambda x: x.astype('category'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kAITuf0NXg3"
      },
      "source": [
        " The data didv't need to be changed to categorical cuz it gave the same results as it's onbject so there is no need to change it.\n",
        "\n",
        " ---- "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBmpJdXr6FEo"
      },
      "source": [
        "\n",
        "###**extract numeric and categorical feature**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-paaaSY0XPfG"
      },
      "source": [
        "---\n",
        "In this step we are splitting the numeric and the categorical values to be able to deal with them later when we want to change the catigorical to numeric.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv-tVCNgN1PF",
        "outputId": "0dad9909-a2b6-4982-f15f-a32477ce4fb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numeric features: ['gender', 'idg', 'condtn', 'wave', 'round', 'position', 'positin1', 'order', 'partner', 'pid', 'int_corr', 'samerace', 'age_o', 'race_o', 'pf_o_att', 'pf_o_sin', 'pf_o_int', 'pf_o_fun', 'pf_o_amb', 'pf_o_sha', 'attr_o', 'sinc_o', 'intel_o', 'fun_o', 'amb_o', 'shar_o', 'like_o', 'prob_o', 'met_o', 'age', 'field_cd', 'race', 'imprace', 'imprelig', 'goal', 'date', 'go_out', 'career_c', 'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga', 'exphappy', 'expnum', 'attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1', 'attr4_1', 'sinc4_1', 'intel4_1', 'fun4_1', 'amb4_1', 'shar4_1', 'attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1', 'attr3_1', 'sinc3_1', 'fun3_1', 'intel3_1', 'amb3_1', 'attr5_1', 'sinc5_1', 'intel5_1', 'fun5_1', 'amb5_1', 'attr', 'sinc', 'intel', 'fun', 'amb', 'shar', 'like', 'prob', 'met', 'match_es', 'attr1_s', 'sinc1_s', 'intel1_s', 'fun1_s', 'amb1_s', 'shar1_s', 'attr3_s', 'sinc3_s', 'intel3_s', 'fun3_s', 'amb3_s', 'satis_2', 'length', 'numdat_2', 'attr7_2', 'sinc7_2', 'intel7_2', 'fun7_2', 'amb7_2', 'shar7_2', 'attr1_2', 'sinc1_2', 'intel1_2', 'fun1_2', 'amb1_2', 'shar1_2', 'attr4_2', 'sinc4_2', 'intel4_2', 'fun4_2', 'amb4_2', 'shar4_2', 'attr2_2', 'sinc2_2', 'intel2_2', 'fun2_2', 'amb2_2', 'shar2_2', 'attr3_2', 'sinc3_2', 'intel3_2', 'fun3_2', 'amb3_2', 'attr5_2', 'sinc5_2', 'intel5_2', 'fun5_2', 'amb5_2', 'you_call', 'them_cal', 'date_3', 'numdat_3', 'num_in_3', 'attr1_3', 'sinc1_3', 'intel1_3', 'fun1_3', 'amb1_3', 'shar1_3', 'attr7_3', 'sinc7_3', 'intel7_3', 'fun7_3', 'amb7_3', 'shar7_3', 'attr4_3', 'sinc4_3', 'intel4_3', 'fun4_3', 'amb4_3', 'shar4_3', 'attr2_3', 'sinc2_3', 'intel2_3', 'fun2_3', 'amb2_3', 'shar2_3', 'attr3_3', 'sinc3_3', 'intel3_3', 'fun3_3', 'amb3_3', 'attr5_3', 'sinc5_3', 'intel5_3', 'fun5_3', 'amb5_3']\n",
            "categorical features: ['field', 'undergra', 'mn_sat', 'tuition', 'from', 'zipcode', 'income', 'career']\n"
          ]
        }
      ],
      "source": [
        "# we extract numeric features and categorical features names\n",
        "# for later use\n",
        "\n",
        "# numeric features can be selected by: (based on the data.info() output )\n",
        "features_numeric = list(X.select_dtypes(include=['float64', 'int64']))\n",
        "\n",
        "# categorical features can be selected by: (based on the df2.info() output )\n",
        "features_categorical = list(X.select_dtypes(include=['object']))\n",
        "\n",
        "print('numeric features:', features_numeric)\n",
        "print('categorical features:', features_categorical)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Nb3UFSzBKZa"
      },
      "source": [
        "---\n",
        "###**FuLL PIPILINE**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TiL-d3iR5bn"
      },
      "source": [
        "This is the most important step in the preprocessing, it's where i can Fill the NAN values and also convert the categorical values into numerical by using onehotEncoding, and also we scale the data by StandardScaler.\n",
        "\n",
        " ---\n",
        "\n",
        "- The first pipe line for numeric feature preprocessing. \n",
        "   - **SimpleImputer** : we use it to fill the Nan values.\n",
        "   - **StandardScaler** : to scale the numeric values.\n",
        "- The second pip line for object feature preprocessing.\n",
        "  - **SimpleImputer** : we use it to fill the Nan values.\n",
        "  - **OneHotEncoder** : we use it to convert the objest to numeric values.\n",
        "\n",
        "- The last column in the full pipline we use it to call the first and second pip line.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5N8ASmYmBPK5"
      },
      "outputs": [],
      "source": [
        "#import all the libraries that we use it the follwing steps \n",
        "import numpy as np\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "# define a pipe line for numeric feature preprocessing\n",
        "transformer_numeric = Pipeline(\n",
        "    steps=[\n",
        "        ('imputer', SimpleImputer()),\n",
        "        ('scaler', StandardScaler())]\n",
        ")\n",
        "\n",
        "# define a pipe line for object feature preprocessing\n",
        "transformer_categorical = Pipeline(\n",
        "    steps=[\n",
        "        ('imputer', SimpleImputer(strategy='constant')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ]\n",
        ")\n",
        "\n",
        "# define the preprocessor \n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', transformer_numeric, features_numeric),\n",
        "        ('cat', transformer_categorical, features_categorical)\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "4MtiIWEyBPOI"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bC-9W1W6iuR"
      },
      "source": [
        "---\n",
        "---\n",
        "#**modeling** \n",
        "\n",
        "---\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQzdP8dqhdwY"
      },
      "source": [
        "--- \n",
        "**my plans for thr trials**\n",
        "\n",
        "im planning to use:\n",
        "\n",
        "- Random forst with Grid search  \n",
        "- Logistic regresstion with grid earch\n",
        "- losgistic regresstion with validation set\n",
        "- losgistic regresstion with random forest\n",
        "- losgistic regresstion with Bayes search\n",
        "- logistic regression with feature selection \n",
        "- XGBClassifier with grid earch\n",
        "- XGBClassifier with validation set\n",
        "- XGBClassifier with  random forest\n",
        "- XGBClassifier regresstion with Bayes search\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xkTCybBX5PV"
      },
      "source": [
        "\n",
        "##**Trial_1**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lrl-ZzDFVIA8"
      },
      "source": [
        "\n",
        "###Random forest with Grid Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSUtklph4CEG"
      },
      "source": [
        "---\n",
        "Random forest is a flexible, easy to use machine learning algorithm that produces, even without hyper-parameter tuning\n",
        " \n",
        "im expecting a great result most of the time. It is also one of the most used algorithms, because of its simplicity and diversity.\n",
        "\n",
        "And also im using Hyperparameter tuning : **Grid search** and it allowed us to narrow down the range for each hyperparameter.\n",
        "\n",
        "---\n",
        "\n",
        "**Hyperparameters used in Grid search** :\n",
        "\n",
        "---\n",
        "---\n",
        "- **n_estimators** : A object of that type is instantiated for each grid point. This is assumed to implement the scikit-learn estimator interface. Either estimator needs to provide a score function, or scoring must be passed.\n",
        "\n",
        "- **max_depth** :the depth of the tree.\n",
        "\n",
        "- **n_jobs** : Number of jobs to run in paralle.\n",
        "\n",
        "- **cv** : int, cross-validation generator or an iterable\n",
        "\n",
        "- **verbose** : Controls the verbosity: the higher, the more messages.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "n1Dkhhp69daI"
      },
      "outputs": [],
      "source": [
        "# combine the preprocessor with the model as a full tunable pipeline\n",
        "# here we call the full pip line with the classifier RandomForestClassifier\n",
        "full_pipline = Pipeline(steps=[('preprocessor', preprocessor),('my_classifier', RandomForestClassifier(),)])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixxw71wJt__D"
      },
      "source": [
        "---\n",
        "We fit the model with full_pipline so all the steps excist in the pipline will be performed on the x,y (the features and the label)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9EDMm-9S9dc_"
      },
      "outputs": [],
      "source": [
        "# The pipeline object can be used like any sk-learn model\n",
        "full_pipline = full_pipline.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSdfm7eBk9y-"
      },
      "source": [
        "---\n",
        "This step is really important bescause in here we perform the same preprocesing\n",
        "\n",
        " steps in the test file and that's by predictiong using the **full_pipline**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "euB72g76EB-4"
      },
      "outputs": [],
      "source": [
        "# predect the output for the test data using the full_pipline do all the preprocessing will be done on the test file too\n",
        "y_test_pred = full_pipline.predict_proba(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5EZKzP2oimu"
      },
      "source": [
        "--- \n",
        "---\n",
        "\n",
        "**Hyperparameters used in Grid search** :\n",
        "\n",
        "---\n",
        "---\n",
        "- **n_estimators** : A object of that type is instantiated for each grid point. This is assumed to implement the scikit-learn estimator interface. Either estimator needs to provide a score function, or scoring must be passed.\n",
        "\n",
        "- **max_depth** :the depth of the tree.\n",
        "\n",
        "- **n_jobs** : Number of jobs to run in paralle.\n",
        "\n",
        "- **cv** : int, cross-validation generator or an iterable\n",
        "\n",
        "- **verbose** : Controls the verbosity: the higher, the more messages.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhv0DTtIL-n3",
        "outputId": "b80a3593-ce94-48a8-81cc-27157b1d1029"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n",
            "best score 0.831188762194597\n",
            "best score {'my_classifier__max_depth': 10, 'my_classifier__n_estimators': 40, 'preprocessor__num__imputer__strategy': 'mean'}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# here we specify the search space\n",
        "# `__` denotes an attribute of the preceeding name\n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
        "param_grid = {\n",
        "    'preprocessor__num__imputer__strategy': ['mean'],\n",
        "    # my_classifier__n_estimators points to my_classifier->n_estimators y\n",
        "    'my_classifier__n_estimators': [20, 30, 40],  \n",
        "    'my_classifier__max_depth':[10, 20, 30]       \n",
        "}\n",
        "\n",
        "# cv=2 means two-fold cross-validation\n",
        "# n_jobs means the cucurrent number of jobs\n",
        "# (on colab since we only have two cpu cores, we set it to 2)\n",
        "grid_search = GridSearchCV(\n",
        "    full_pipline, param_grid, cv=2, verbose=1, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "print('best score {}'.format(grid_search.best_score_))\n",
        "print('best score {}'.format(grid_search.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpfES2y9mRGv"
      },
      "source": [
        "- After performaing the model with the Grid Search, i realized that the model perform good.it gave me an accuracy = 0.827.\n",
        "\n",
        "- **\"my thoughts\"** \n",
        "\n",
        " - i thought the modell will give me a higer accuracy than that.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "opDm1K6VMH2V"
      },
      "outputs": [],
      "source": [
        "# predicting the output for the the test value \n",
        "y_test_pred_ = grid_search.predict_proba(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "mPIx2QI89dff"
      },
      "outputs": [],
      "source": [
        "# for writting the results in a file on drive\n",
        "dummy = pd.DataFrame({'id':id_,'match': y_test_pred[:,1]})\n",
        "dummy.to_csv('/content/drive/MyDrive/DM_assignment2/assignment2_RF.csv', encoding='utf-8', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**With logistic Regression**"
      ],
      "metadata": {
        "id": "EKF9bLX2WMkK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uav5V8z45PeN"
      },
      "source": [
        "\n",
        "##**Trial_2**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8eMaMpB5McF"
      },
      "source": [
        "###Grid Search with Cross-validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jF28CbpHvCBl"
      },
      "source": [
        "---\n",
        "Logistic regression is not a classifier. It is a probability/risk estimator, it allows for and expects \"close calls\". It will lead to optimum decision making because it does not try to trick the predictive signal into incorporating a utility function that is implicit whenever you classify observations.\n",
        "\n",
        "---\n",
        "\n",
        "im expecting cross validation with the logistic regression to give a high a ccuracy than the grid search and validation set since it does not try to trick the predictive signal into incorporating.\n",
        "\n",
        "---\n",
        "\n",
        "**Hyperparameters used in Grid search** :\n",
        "\n",
        "---\n",
        "- **penalty** : the regulrization to control overfitting \n",
        "\n",
        "- **C** : is inverse of regularization, the larger the C, the smaller is regularization, means that your algo is more prone to overfit the data\n",
        "\n",
        "- **n_jobs** : Number of jobs to run in paralle.\n",
        "\n",
        "- **cv** : int, cross-validation generator or an iterable\n",
        "\n",
        "- **verbose** : Controls the verbosity: the higher, the more messages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "-mMveK7WxiMK"
      },
      "outputs": [],
      "source": [
        "# combine the preprocessor with the model as a full tunable pipeline\n",
        "# here we call the full pip line with the classifier RandomForestClassifier\n",
        "full_pipline = Pipeline(steps=[('preprocessor', preprocessor),('my_classifier', LogisticRegression(),)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn18dvxBx9jJ"
      },
      "source": [
        "---\n",
        "We fit the model with full_pipline so all the steps excist in the pipline will be performed on the x,y (the features and the label)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIFtpmP2xlwi"
      },
      "outputs": [],
      "source": [
        "# The pipeline object can be used like any sk-learn model\n",
        "full_pipline = full_pipline.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBEVZhrb9cH-"
      },
      "source": [
        "--- \n",
        "In order to find the optimal value of the tuning parameter, a grid search needs to be conducted, and the optimal model is the one with the lowest GBIC (Generalized Bayesian Information Criterion)\n",
        "\n",
        "---\n",
        "\n",
        "**Hyperparameters used in Grid search** :\n",
        "\n",
        "---\n",
        "---\n",
        "- **penalty** : the regulrization to control overfitting \n",
        "\n",
        "- **C** : is inverse of regularization, the larger the C, the smaller is regularization, means that your algo is more prone to overfit the data\n",
        "\n",
        "- **n_jobs** : Number of jobs to run in paralle.\n",
        "\n",
        "- **cv** : int, cross-validation generator or an iterable\n",
        "\n",
        "- **verbose** : Controls the verbosity: the higher, the more messages.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd9Rh5ix9dvX",
        "outputId": "f21a8564-dcb8-4b08-ba1b-d3474ec2ec99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n",
            "best score 0.8568706602967452\n",
            "best score {'my_classifier__C': 0.004832930238571752, 'my_classifier__penalty': 'l2', 'my_classifier__solver': 'newton-cg', 'preprocessor__num__imputer__strategy': 'mean'}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\n",
        "    'preprocessor__num__imputer__strategy': ['mean'],\n",
        "    'my_classifier__penalty' : ['l2'],  \n",
        "    'my_classifier__C' : np.logspace(-4, 4, 20),\n",
        "    'my_classifier__solver': ['newton-cg']      \n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    full_pipline, param_grid, cv=2, verbose=1, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "print('best score {}'.format(grid_search.best_score_))\n",
        "print('best score {}'.format(grid_search.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UABXU3pE5CpB"
      },
      "source": [
        "- After performaing the model with the Grid Search, i realized that the model perform IS good.it gave me an accuracy = 0.856.\n",
        "\n",
        "- **\"my thoughts\"** \n",
        "\n",
        " - i thought the modell will give me a higer accuracy than 0.856.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Qpdm4rLIRZvT"
      },
      "outputs": [],
      "source": [
        "# predict the the test data\n",
        "y_test_pred_ = grid_search.predict_proba(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "RNLNBR8LRZym"
      },
      "outputs": [],
      "source": [
        "dummy = pd.DataFrame({'id':id_,'match': y_test_pred_[:,1]})\n",
        "dummy.to_csv('/content/drive/MyDrive/DM_assignment2/assignment2_LG.csv', encoding='utf-8', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWIBBbOtvwJj"
      },
      "source": [
        "\n",
        "##**Trial_3**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqIG4_K77D-b"
      },
      "source": [
        "### Grid Search with validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VILR1W7f-J4y"
      },
      "source": [
        "---\n",
        "in validation set we are splitting data to have a validation set \n",
        "\n",
        "---\n",
        "im expecting this trial will not going to give a pretty got accuracy comparing to cross validation.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY1evm_97HUq",
        "outputId": "5d69378e-d176-4061-b3a5-d38bf53be14f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "best score 0.860885275519422\n",
            "best score {'my_classifier__C': 0.012742749857031334, 'my_classifier__penalty': 'l2', 'my_classifier__solver': 'newton-cg', 'preprocessor__num__imputer__strategy': 'mean'}\n"
          ]
        }
      ],
      "source": [
        "# Further split the original training set to a train and a validation set\n",
        "X_train2, X_val, y_train2, y_val = train_test_split(\n",
        "    X, y, train_size = 0.8, stratify = y, random_state = 2022)\n",
        "\n",
        "# Create a list where train data indices are -1 and validation data indices are 0\n",
        "# X_train2 (new training set), X_train\n",
        "split_index = [-1 if x in X_train2.index else 0 for x in X.index]\n",
        "\n",
        "# Use the list to create PredefinedSplit\n",
        "pds = PredefinedSplit(test_fold = split_index)\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    full_pipline, param_grid, cv=pds, verbose=1, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "\n",
        "# here we still use X_train; but the grid search model\n",
        "# will use our predefined split internally to determine \n",
        "# which sample belongs to the validation set\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "print('best score {}'.format(grid_search.best_score_))\n",
        "print('best score {}'.format(grid_search.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19QX6YS-760Y"
      },
      "source": [
        "- After performaing the model with the validation set, i realized that the model perform pretty well.it gave me an accuracy = 0.860. and that wasn't expecting.\n",
        "\n",
        "- **\"my thoughts\"** \n",
        "\n",
        " - i thought the modell will give me a lower accuracy but it gave a pretty good one, accuracy = 0.860.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "wettQrsW7HX6"
      },
      "outputs": [],
      "source": [
        "# predict the test data\n",
        "y_test_pred_ = grid_search.predict_proba(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "tEBZz_IL7Ha3"
      },
      "outputs": [],
      "source": [
        "dummy = pd.DataFrame({'id':id_,'match': y_test_pred_[:,1]})\n",
        "dummy.to_csv('/content/drive/MyDrive/DM_assignment2/assignment2_LG_gsv.csv', encoding='utf-8', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "scYPXJAT7HgA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhDYdNRBv0ws"
      },
      "source": [
        "\n",
        "##**Trial_4**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qSdU95-6uah"
      },
      "source": [
        "### Random Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rET6vg9b88WW"
      },
      "source": [
        "---\n",
        "Random search is a basic improvement to grid search. The search process continues until the predetermined iteration number or the desired accuracy are reached. Random search is similar to grid search, but has been proven to produce better results\n",
        "\n",
        "- it' expected that it will do preety well\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI282DvKRZ6C",
        "outputId": "7dea6b32-fbfd-4b20-9185-7115d8dd9c90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
            "best score 0.8604079412006241\n",
            "best score {'preprocessor__num__imputer__strategy': 'mean', 'my_classifier__solver': 'newton-cg', 'my_classifier__penalty': 'l2', 'my_classifier__C': 0.03359818286283781}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "\n",
        "param_grid = {\n",
        "    'preprocessor__num__imputer__strategy': ['mean'],\n",
        "    # preprocessor__num__imputer__strategy points to preprocessor->num (a Pipeline)-> imputer -> strategy\n",
        "    'my_classifier__penalty' : ['l2'],  \n",
        "    'my_classifier__C' : np.logspace(-4, 4, 20),\n",
        "    'my_classifier__solver': ['newton-cg']      \n",
        "} \n",
        "\n",
        "grid_search = RandomizedSearchCV(\n",
        "    full_pipline, param_grid, cv=pds, verbose=1, n_jobs=2, \n",
        "    # number of random trials\n",
        "    n_iter=10,\n",
        "    scoring='roc_auc')\n",
        "\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "print('best score {}'.format(grid_search.best_score_))\n",
        "print('best score {}'.format(grid_search.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfcKtTUi-mHX"
      },
      "source": [
        "---\n",
        "- After performaing the model with the validation set, i realized that the model perform pretty well.it gave me an accuracy = 0.860. and that wasn't expecting.\n",
        "\n",
        "- **\"my thoughts\"** \n",
        "\n",
        " - i thought the modell will give me a lower accuracy but it gave a pretty good one, accuracy = 0.860.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "hZijOgXpB9bw"
      },
      "outputs": [],
      "source": [
        "# predict the test data\n",
        "y_test_pred_ = grid_search.predict_proba(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "FxchCddiB9fH"
      },
      "outputs": [],
      "source": [
        "dummy = pd.DataFrame({'id':id_,'match': y_test_pred_[:,1]})\n",
        "dummy.to_csv('/content/drive/MyDrive/DM_assignment2/assignment2_LG_gs.csv', encoding='utf-8', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "x0v2BM7SCkCQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5vSfSXEv5ty"
      },
      "source": [
        "\n",
        "##**Trial_5**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlj7X0TlCkhP"
      },
      "source": [
        "### Bayes Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht-9EhSj-vF9"
      },
      "source": [
        "---\n",
        "\n",
        "Bayesian Optimization, By assuming an unknown objective function that gets an input, the initial goal was to discover an optimal solution that maximises or decreases the function value. Bayesian optimization is an iterative process\n",
        "\n",
        "- it's expected that it will do the best performance \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkv4LbvhF4sx",
        "outputId": "219557f1-48a5-4ea7-f5ab-e7416e18fa64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (21.10.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.21.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-eN0hNZF4wS",
        "outputId": "24d2e9c2-2467-4170-e117-a5be21893d12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "best score 0.8608955407735895\n",
            "best score OrderedDict([('my_classifier__C', 0.012742749857031334), ('my_classifier__penalty', 'l2'), ('preprocessor__num__imputer__strategy', 'mean')])\n"
          ]
        }
      ],
      "source": [
        "# Let's try this with SVM model\n",
        "from skopt import BayesSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'preprocessor__num__imputer__strategy': ['mean'],\n",
        "    # preprocessor__num__imputer__strategy points to preprocessor->num (a Pipeline)-> imputer -> strategy\n",
        "    'my_classifier__penalty' : [ 'l2'],  \n",
        "     # my_classifier__n_estimators points to my_classifier->n_estimators \n",
        "    'my_classifier__C' : np.logspace(-4, 4, 20),\n",
        "}\n",
        "bayes_search = BayesSearchCV(full_pipline, param_grid, cv=pds, verbose=1, n_jobs=2, \n",
        "    # number of random trials\n",
        "    n_iter=10,\n",
        "    scoring='roc_auc')\n",
        "\n",
        "\n",
        "bayes_search.fit(X, y)\n",
        "\n",
        "print('best score {}'.format(bayes_search.best_score_))\n",
        "print('best score {}'.format(bayes_search.best_params_))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvyrVDqOANvl"
      },
      "source": [
        "---\n",
        "- After performaing the model with the validation set, i realized that the model perform pretty well.it gave me an accuracy = 0.860. and that wasn't expecting.\n",
        "\n",
        "- **\"my thoughts\"** \n",
        "\n",
        " - i thought the modell will give me a lower accuracy but it gave a pretty good one, accuracy = 0.860.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "YOlx2cmTF5Ax"
      },
      "outputs": [],
      "source": [
        "# predict the test data\n",
        "y_test_pred_ = bayes_search.predict_proba(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "H5oE3fILQCOX"
      },
      "outputs": [],
      "source": [
        "dummy = pd.DataFrame({'id':id_,'match': y_test_pred_[:,1]})\n",
        "dummy.to_csv('/content/drive/MyDrive/DM_assignment2/assignment2_LG_bs.csv', encoding='utf-8', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2exosiQwBxy"
      },
      "source": [
        "\n",
        "##**Trial_6**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI-NMTfeeo5V"
      },
      "source": [
        "### feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpkVX-DxBgnF"
      },
      "source": [
        "---\n",
        "- it's expecting that this trial will give the highest performance and a high accuracy\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "6XQnoHEaetFT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# combine the preprocessor with the model as a full tunable pipeline\n",
        "# we gave them a name so we can set their hyperparameters\n",
        "full_pipline = Pipeline( steps=[('preprocessor', preprocessor),('selector', SelectKBest(mutual_info_classif, k=5)),('my_classifier', LogisticRegression(),)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNYkYneUetmk"
      },
      "outputs": [],
      "source": [
        "# The pipeline object can be used like any sk-learn model\n",
        "full_pipline = full_pipline.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predect the output for the test data using the full_pipline do all the preprocessing will be done on the test file too\n",
        "y_test_pred = full_pipline.predict_proba(test)"
      ],
      "metadata": {
        "id": "KUSQyOipXoii"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "4UoLn8ipetrs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7274aa60-98b7-4418-dcf5-f7dbeb36b797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 150 candidates, totalling 300 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_supervised.py:65: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score 0.8560072217605473\n",
            "best score {'my_classifier__C': 0.0062505519252739694, 'my_classifier__penalty': 'l2', 'my_classifier__solver': 'newton-cg', 'preprocessor__num__imputer__strategy': 'mean', 'selector__k': 100}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# here we specify the search space\n",
        "# `__` denotes an attribute of the preceeding name\n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
        "param_grid = {\n",
        "    'preprocessor__num__imputer__strategy': ['mean'],\n",
        "    'selector__k': [100, 150, 160],\n",
        "    'my_classifier__penalty' : ['l2'],   \n",
        "    'my_classifier__C' : np.logspace(-4, 4 ),\n",
        "    'my_classifier__solver': ['newton-cg']       \n",
        "}\n",
        "\n",
        "# cv=2 means two-fold cross-validation\n",
        "# n_jobs means the cucurrent number of jobs\n",
        "# (on colab since we only have two cpu cores, we set it to 2)\n",
        "grid_search = GridSearchCV(\n",
        "    full_pipline, param_grid, cv=2, verbose=1, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "print('best score {}'.format(grid_search.best_score_))\n",
        "print('best score {}'.format(grid_search.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "- After performaing the model with the validation set, i realized that the model perform quite bad .it gave me an accuracy = 0.850. and that wasn't expecting.\n",
        "\n",
        "- **\"my thoughts\"** \n",
        "\n",
        " - i thought the modell will give me a hugher accuracy\n",
        "---"
      ],
      "metadata": {
        "id": "RUsB9eCo4L_r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "fnpOrFusetwt"
      },
      "outputs": [],
      "source": [
        "y_test_pred_ = grid_search.predict_proba(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnL38_fIwiFu"
      },
      "source": [
        "**Observation**:  \n",
        "\n",
        "\n",
        "After using th feature selection we realize that that didn't affect the model acuracy . so using the feature selection with the LOGISTIC regression model didn'y really go as expected.the accuracy of the model decreased from 0.86664 to 0.86365"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**With XGBClassifier**"
      ],
      "metadata": {
        "id": "mQjKEivuV6fi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCOozkYGDApE"
      },
      "source": [
        "---\n",
        "##**Trial_7** \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QzK-3jn1Isi"
      },
      "source": [
        " in this trial and the upcomming trials im using the **XGBClassifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31k7CalWIuTz"
      },
      "source": [
        "--- \n",
        "\n",
        "**Hyperparameters used in Grid search** :\n",
        "\n",
        "---\n",
        "- **max_depth** : Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit \n",
        "\n",
        "- **subsamble** : Same as the subsample of GBM. Denotes the fraction of observations to be randomly samples for each tree.\n",
        "\n",
        "- **nthread** : the number og threads to use for loading data\n",
        "\n",
        "- **colsample_bytree** : corresponds to the fraction of features (the columns) to use. By default it is set to 1 meaning that we will use all features.\n",
        "\n",
        "- **n_estimators** : A object of that type is instantiated for each grid point. This is assumed to implement the scikit-learn estimator interface. Either estimator needs to provide a score function, or scoring must be passed.\n",
        "\n",
        "- **n_jobs** : Number of jobs to run in paralle.\n",
        "\n",
        "- **cv** : int, cross-validation generator or an iterable\n",
        "\n",
        "- **verbose** : Controls the verbosity: the higher, the more messages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "843MQ9Hvm-Wm"
      },
      "source": [
        "###**Grid Search with Cross-validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "e7fOLCMMet8E"
      },
      "outputs": [],
      "source": [
        "# calling the full pipline\n",
        "full_pipline = Pipeline(steps=[('preprocessor', preprocessor),('my_classifier', XGBClassifier(),)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "KZ3Ytsjqet-b"
      },
      "outputs": [],
      "source": [
        "# The pipeline object can be used like any sk-learn model\n",
        "full_pipline = full_pipline.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predect the output for the test data using the full_pipline do all the preprocessing will be done on the test file too\n",
        "y_test_pred = full_pipline.predict_proba(test)"
      ],
      "metadata": {
        "id": "TmCG3l3wtveU"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQa6jCBtMUrr"
      },
      "source": [
        "--- \n",
        "\n",
        "**Hyperparameters used in Grid search** :\n",
        "\n",
        "---\n",
        "- **max_depth** : Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit \n",
        "\n",
        "- **subsamble** : Same as the subsample of GBM. Denotes the fraction of observations to be randomly samples for each tree.\n",
        "\n",
        "- **nthread** : the number og threads to use for loading data\n",
        "\n",
        "- **colsample_bytree** : corresponds to the fraction of features (the columns) to use. By default it is set to 1 meaning that we will use all features.\n",
        "\n",
        "- **n_estimators** : A object of that type is instantiated for each grid point. This is assumed to implement the scikit-learn estimator interface. Either estimator needs to provide a score function, or scoring must be passed.\n",
        "\n",
        "- **n_jobs** : Number of jobs to run in paralle.\n",
        "\n",
        "- **cv** : int, cross-validation generator or an iterable\n",
        "\n",
        "- **verbose** : Controls the verbosity: the higher, the more messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fumfgtR3euDZ",
        "outputId": "61db24bb-5cd3-485f-e5f0-aa290f781e92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "best score 0.8843569370157903\n",
            "best score {'my_classifier__colsample_bytree': 0.9, 'my_classifier__learning_rate': 0.005, 'my_classifier__max_depth': 6, 'my_classifier__n_estimators': 2000, 'my_classifier__nthread': 5, 'my_classifier__subsamble': 0.9}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# here we specify the search space\n",
        "# `__` denotes an attribute of the preceeding name\n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
        "param_grid = {\n",
        "        \"my_classifier__max_depth\" : [6],\n",
        "        'my_classifier__subsamble' : [0.9],\n",
        "        'my_classifier__nthread' :[5],\n",
        "        'my_classifier__colsample_bytree' :[0.9],\n",
        "        'my_classifier__learning_rate' :[0.005],\n",
        "        'my_classifier__n_estimators':  [2000]\n",
        "}\n",
        "\n",
        "# cv=2 means two-fold cross-validation\n",
        "# n_jobs means the cucurrent number of jobs\n",
        "# (on colab since we only have two cpu cores, we set it to 2)\n",
        "grid_search = GridSearchCV(\n",
        "    full_pipline, param_grid, cv=5, verbose=1, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "print('best score {}'.format(grid_search.best_score_))\n",
        "print('best score {}'.format(grid_search.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "10WA0xRreuGD"
      },
      "outputs": [],
      "source": [
        "# grid_search.fit(X,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VskzZoacGhyc"
      },
      "source": [
        "---\n",
        "- After performaing the model i realized that the model perform pretty good.it gave me a high accuracy = 0.884.\n",
        "\n",
        "- **\"my thoughts\"** \n",
        "\n",
        " - the classifer handel the data pretty well and it was able to perform well with the hyperparameter tuning \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "8HoONb5119uo"
      },
      "outputs": [],
      "source": [
        "#predict the test dat \n",
        "y_test_pred_ = grid_search.predict_proba(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "1PjQ9zNP19xY"
      },
      "outputs": [],
      "source": [
        "dummy = pd.DataFrame({'id':id_,'match': y_test_pred_[:,1]})\n",
        "dummy.to_csv('/content/drive/MyDrive/DM_assignment2/assignment2_XGB2.csv', encoding='utf-8', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE62kTWoDkNy"
      },
      "source": [
        "---\n",
        "##**Trial_8**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbEeoyZAQ3NA"
      },
      "source": [
        "---\n",
        "### Grid Search with validation set\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87GO4lFcHqtC"
      },
      "source": [
        "---\n",
        "in validation set we are splitting data to have a validation set \n",
        "\n",
        "---\n",
        "im expecting this trial will not going to give a pretty got accuracy comparing to cross validation.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPGb2wyMQ5aB",
        "outputId": "f2a295ca-c13c-43a0-b42c-a0fb7b7053cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "best score 0.8797990063233966\n",
            "best score {'my_classifier__colsample_bytree': 0.9, 'my_classifier__learning_rate': 0.005, 'my_classifier__max_depth': 6, 'my_classifier__n_estimators': 2000, 'my_classifier__nthread': 5, 'my_classifier__subsamble': 0.9}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "\n",
        "# Further split the original training set to a train and a validation set\n",
        "X_train1, X_val, y_train1, y_val = train_test_split(\n",
        "    X, y, train_size = 0.8, stratify = y, random_state = 2022)\n",
        "\n",
        "# Create a list where train data indices are -1 and validation data indices are 0\n",
        "# X_train2 (new training set), X_train\n",
        "split_index = [-1 if x in X_train1.index else 0 for x in X.index]\n",
        "\n",
        "# Use the list to create PredefinedSplit\n",
        "pds = PredefinedSplit(test_fold = split_index)\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    full_pipline, param_grid, cv=pds, verbose=1, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "\n",
        "# here we still use X_train; but the grid search model\n",
        "# will use our predefined split internally to determine \n",
        "# which sample belongs to the validation set\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "print('best score {}'.format(grid_search.best_score_))\n",
        "print('best score {}'.format(grid_search.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urLdrIswHEzU"
      },
      "source": [
        "---\n",
        "- After performaing the model i realized that the model perform pretty good.it gave me a good accuracy = 0.879."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89vsPZkVDtcq"
      },
      "source": [
        "---\n",
        "##**Trial_9**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qtjet8dplXjQ"
      },
      "source": [
        "---\n",
        "###Random Search\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmZEwqNPHmyz"
      },
      "source": [
        "---\n",
        "Random search is a basic improvement to grid search. The search process continues until the predetermined iteration number or the desired accuracy are reached. Random search is similar to grid search, but has been proven to produce better results\n",
        "\n",
        "- it' expected that it will do preety well\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBiEa66XmP31",
        "outputId": "d1e011e2-05a2-4f55-b794-2d0fa0afe69d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 1 is smaller than n_iter=30. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score 0.8797990063233966\n",
            "best score {'my_classifier__subsamble': 0.9, 'my_classifier__nthread': 5, 'my_classifier__n_estimators': 2000, 'my_classifier__max_depth': 6, 'my_classifier__learning_rate': 0.005, 'my_classifier__colsample_bytree': 0.9}\n",
            ">>>>>>>>>> pds =  PredefinedSplit(test_fold=array([-1, -1, ..., -1, -1]))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "\n",
        "\n",
        "grid_search = RandomizedSearchCV(\n",
        "    full_pipline, param_grid, cv=pds, verbose=1, n_jobs=2, \n",
        "    # number of random trials\n",
        "    n_iter=30,\n",
        "    scoring='roc_auc')\n",
        "\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "print('best score {}'.format(grid_search.best_score_))\n",
        "print('best score {}'.format(grid_search.best_params_))\n",
        "print('>>>>>>>>>> pds = ', pds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIxVfOeDHNYj"
      },
      "source": [
        "---\n",
        "- After performaing the model i realized that the model perform pretty good.it gave me a good accuracy = 0.879.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "6vj2pU58197Y"
      },
      "outputs": [],
      "source": [
        "# predection on the test data\n",
        "y_test_pred_ = grid_search.predict_proba(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "MiNpdnzhoAKc"
      },
      "outputs": [],
      "source": [
        "dummy = pd.DataFrame({'id':id_,'match': y_test_pred_[:,1]})\n",
        "dummy.to_csv('/content/drive/MyDrive/DM_assignment2/assignment2_XGB_R.csv', encoding='utf-8', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHTOcNpyDx1E"
      },
      "source": [
        "---\n",
        "##**Trial_10**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtvkS2OKoOsF"
      },
      "source": [
        "---\n",
        "### Bayesian Search\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLTwLLT6Hj4Z"
      },
      "source": [
        "---\n",
        "\n",
        "Bayesian Optimization, By assuming an unknown objective function that gets an input, the initial goal was to discover an optimal solution that maximises or decreases the function value. Bayesian optimization is an iterative process\n",
        "\n",
        "- it's expected that it will do the best performance \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6ol0iedoAPU",
        "outputId": "3708c3b2-7dc8-4078-b169-e53277a5171f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "best score 0.8797990063233966\n",
            "best score OrderedDict([('my_classifier__colsample_bytree', 0.9), ('my_classifier__learning_rate', 0.005), ('my_classifier__max_depth', 6), ('my_classifier__n_estimators', 2000), ('my_classifier__nthread', 5), ('my_classifier__subsamble', 0.9)])\n"
          ]
        }
      ],
      "source": [
        "# Let's try this with SVM model\n",
        "from skopt import BayesSearchCV\n",
        "\n",
        "bayes_search = BayesSearchCV(full_pipline, param_grid, cv=pds, verbose=1, n_jobs=2, \n",
        "    # number of random trials\n",
        "    n_iter=10,\n",
        "    scoring='roc_auc')\n",
        "\n",
        "\n",
        "bayes_search.fit(X, y)\n",
        "\n",
        "print('best score {}'.format(bayes_search.best_score_))\n",
        "print('best score {}'.format(bayes_search.best_params_))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MizUq3YTHdqD"
      },
      "source": [
        "---\n",
        "- After performaing the model i realized that the model perform pretty good.it gave me a good accuracy = 0.8790.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "sNL8EWIQoAT8"
      },
      "outputs": [],
      "source": [
        "# predict on the test data\n",
        "y_test_pred_ = bayes_search.predict_proba(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "6tNVuXwEoAW3"
      },
      "outputs": [],
      "source": [
        "dummy = pd.DataFrame({'id':id_,'match': y_test_pred_[:,1]})\n",
        "dummy.to_csv('/content/drive/MyDrive/DM_assignment2/assignment2_XGB_BS.csv', encoding='utf-8', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpTPsx2gisjM"
      },
      "source": [
        "#**Questions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxL8VVX_iwU1"
      },
      "source": [
        "--- \n",
        "**1- Why a simple linear regression model (without any activation function) is not good for classification task, compared to Perceptron/Logistic regression?**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwMt9t-liwh1"
      },
      "source": [
        "There are two things that explain why Linear Regression is not suitable for classification. The first one is that Linear Regression deals with continuous values whereas classification problems mandate discrete values.\n",
        "The second problem is regarding the shift in threshold value when new data points are added. Let us take a simple Linear Regression example and fit a line to it. The below graph shows the best fit line. To make the explanation a bit more simple let us take an example of a classification problem in healthcare. Basically, our aim here is to classify whether a person is sick or not.\n",
        "Technically the hypothesis function for linear regression can be used for logistic regression also but there is a problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVDNqv-Diwmc"
      },
      "source": [
        "---\n",
        "**2-What's a decision tree and how it is different to a logistic regression model?**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdKvWIZOiwqN"
      },
      "source": [
        "- The decision trees is a quite popular data mining technique (Hastie, Tibshirani and Friedman, 2009), which is easey of use, robustness with missing data and ease of interpretability. Generally, decision trees are flexible.\n",
        "\n",
        "- Regression models are relatively inflexible, for example, you have to add additional terms, i.e. interaction terms,polynomial terms. \n",
        "And decision trees can deal with missing values without imputation, while regression modelusually has to impute missing values before building the model, although there is not missing data in our data set.\n",
        "And decision trees are nonparametric and highly robust, while regression models are parametric and sensitive to influencing points. \n",
        "We use the Tree node in Enterprise Miner to analyze the transportation data. The Gini reduction method is chosen as the splitting criterion.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb4yMafn8S3M"
      },
      "source": [
        "---\n",
        "**3-What's the difference between grid search and random search?**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i1g9U7o8S6e"
      },
      "source": [
        "- The grid search is an automatic search that searches an area within a range in a grid format.\n",
        "\n",
        "- Grid search is the primary method for hyperparameter optimization and thoroughly searches hyperparameter sets in a custom range.\n",
        "\n",
        "- Grid search can be applied to multiple hyper parameters. Grid search is the simplest search algorithm leading to the most accurate predictions and users can\n",
        "always find the best combination.\n",
        "\n",
        "\n",
        "- A random search algorithm has been proposed to improve the problem in grid search. Random search tries any combination of ranges of values.\n",
        "Compare with grid search, random search can be considered more efficient in high-dimensional space. But random search is unreliable for training\n",
        "some complex models. Bayesian method is recently drawing attention to solve this kind of problem.\n",
        "It combines prior information about the unknown function with sample information, to obtain posterior information of the function distribution by using Bayesian formula.\n",
        "\n",
        "- Random search is a basic improvement to grid search. The search process continues until the predetermined iteration number or the desired accuracy are reached. Random search is similar to grid search, but has been proven to produce\n",
        "better results due to the following two benefits:\n",
        "\n",
        " - **First**, random search can perform better, especially if some hyper-parameters are not evenly distributed. In this search pattern, random searches are relatively more likely to find the optimal configuration than grid searches. \n",
        "     \n",
        "  -  **Secondly**, it is not a promise that random searches will give you the best value, but you can get good value. And the more time\n",
        "you spend, the more likely you are to find a better set of hyper-parameters. Conversely, for grid search, we cannot guarantee better results even with long search times. In most cases, random search is more effective than grid search, but it is still a computationally intensive method. Random searches generally require more time and computational resources than other search methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l6IXW0q8S-0"
      },
      "source": [
        "---\n",
        "**4-What's the difference between bayesian search and random search?**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUjpQQA9GzlR"
      },
      "source": [
        "- Random search is a basic improvement to grid search. The search process continues until the predetermined iteration number or the desired accuracy are reached. Random search is similar to grid search, but has been proven to produce\n",
        "better results due to the following two benefits:\n",
        "\n",
        " - **First**, random search can perform better, especially if some hyper-parameters are not evenly distributed. In this search pattern, random searches are relatively more likely to find the optimal configuration than grid searches. \n",
        "     \n",
        "  -  **Secondly**, it is not a promise that random searches will give you the best value, but you can get good value. And the more time\n",
        "you spend, the more likely you are to find a better set of hyper-parameters. Conversely, for grid search, we cannot guarantee better results even with long search times. In most cases, random search is more effective than grid search, but it is still a computationally intensive method. Random searches generally require more time and computational resources than other search methods.\n",
        "\n",
        "- Bayesian Optimization, By assuming an unknown objective function that gets an input, the initial goal was to discover an optimal solution that maximises or decreases the function value. Bayesian optimization is an iterative process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEIUaS_i8TCL"
      },
      "source": [
        "---\n",
        "**refreances**\n",
        "\n",
        "----\n",
        "- https://www.mwsug.org/proceedings/2009/stats/MWSUG-2009-D02.pdf\n",
        "\n",
        "- https://www.koreascience.or.kr/article/JAKO202009252091916.pdf"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Assignment_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}